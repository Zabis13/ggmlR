#!/usr/bin/env Rscript
# ============================================================================
# GGMLR GPU vs CPU Performance Benchmark
# ============================================================================

library(ggmlR)

cat("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘        GGMLR Performance: GPU (Vulkan) vs CPU Benchmark       â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n")

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ´ĞµÑ€ CPU
n_cores <- parallel::detectCores()
cat(sprintf("CPU: ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ ÑĞ´ĞµÑ€: %d\n", n_cores))

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Vulkan
vulkan_available <- ggml_vulkan_available()
cat(sprintf("GPU: Vulkan %s\n", ifelse(vulkan_available, "Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞ•Ğ", "ĞĞ• Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞ•Ğ")))

if (vulkan_available) {
  n_devices <- ggml_vulkan_device_count()
  cat(sprintf("GPU: ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²: %d\n", n_devices))

  if (n_devices > 0) {
    gpu_name <- ggml_vulkan_device_description(0)
    gpu_mem <- ggml_vulkan_device_memory(0)
    cat(sprintf("GPU: %s\n", gpu_name))
    cat(sprintf("GPU: ĞŸĞ°Ğ¼ÑÑ‚ÑŒ %.2f GB / %.2f GB\n",
                gpu_mem$free / 1e9, gpu_mem$total / 1e9))
  }
}

cat("\n")

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° Ğ½Ğ° CPU
benchmark_cpu <- function(size, iterations = 10) {
  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ as.numeric Ğ´Ğ»Ñ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ğ½Ğ¸Ñ integer overflow
  mem_size <- as.numeric(size) * 4 * 4
  ctx <- ggml_init(mem_size = mem_size)
  ggml_set_no_alloc(ctx, TRUE)

  # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ñ‹
  t1 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
  t2 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
  t3 <- ggml_add(ctx, t1, t2)

  # CPU backend
  backend <- ggml_backend_cpu_init()
  ggml_backend_cpu_set_n_threads(backend, n_cores)
  buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

  # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
  data1 <- rnorm(size)
  data2 <- rnorm(size)
  ggml_backend_tensor_set_data(t1, data1)
  ggml_backend_tensor_set_data(t2, data2)

  # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
  graph <- ggml_build_forward_expand(ctx, t3)
  ggml_backend_graph_compute(backend, graph)

  # Benchmark
  times <- numeric(iterations)
  for (i in 1:iterations) {
    start <- Sys.time()
    ggml_backend_graph_compute(backend, graph)
    times[i] <- as.numeric(Sys.time() - start)
  }

  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
  result <- ggml_backend_tensor_get_data(t3)

  # Cleanup
  ggml_backend_buffer_free(buffer)
  ggml_backend_free(backend)
  ggml_free(ctx)

  list(
    mean_time = mean(times),
    min_time = min(times),
    max_time = max(times),
    sd_time = sd(times),
    gflops = size / mean(times) / 1e9,
    result = result[1:5]  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 5 ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
  )
}

# Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ° Ğ½Ğ° GPU
benchmark_gpu <- function(size, iterations = 10) {
  if (!vulkan_available || ggml_vulkan_device_count() == 0) {
    return(NULL)
  }

  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ as.numeric Ğ´Ğ»Ñ Ğ¸Ğ·Ğ±ĞµĞ¶Ğ°Ğ½Ğ¸Ñ integer overflow
  mem_size <- as.numeric(size) * 4 * 4
  ctx <- ggml_init(mem_size = mem_size)
  ggml_set_no_alloc(ctx, TRUE)

  # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ñ‹
  t1 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
  t2 <- ggml_new_tensor_1d(ctx, GGML_TYPE_F32, size)
  t3 <- ggml_add(ctx, t1, t2)

  # Vulkan backend
  backend <- ggml_vulkan_init(0)
  buffer <- ggml_backend_alloc_ctx_tensors(ctx, backend)

  # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
  data1 <- rnorm(size)
  data2 <- rnorm(size)
  ggml_backend_tensor_set_data(t1, data1)
  ggml_backend_tensor_set_data(t2, data2)

  # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ²
  graph <- ggml_build_forward_expand(ctx, t3)
  ggml_backend_graph_compute(backend, graph)

  # Benchmark
  times <- numeric(iterations)
  for (i in 1:iterations) {
    start <- Sys.time()
    ggml_backend_graph_compute(backend, graph)
    times[i] <- as.numeric(Sys.time() - start)
  }

  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
  result <- ggml_backend_tensor_get_data(t3)

  # Cleanup
  ggml_backend_buffer_free(buffer)
  ggml_vulkan_free(backend)
  ggml_free(ctx)

  list(
    mean_time = mean(times),
    min_time = min(times),
    max_time = max(times),
    sd_time = sd(times),
    gflops = size / mean(times) / 1e9,
    result = result[1:5]
  )
}

# ============================================================================
# Ğ¢ĞµÑÑ‚ 1: Ğ Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ğ¾Ğ²
# ============================================================================
cat("â•â•â• Ğ¢ĞµÑÑ‚ 1: Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°Ñ… â•â•â•\n\n")

sizes <- c(1e6, 5e6, 1e7, 5e7, 1e8, 2e8, 5e8)
iterations <- 50

results_table <- data.frame(
  Size = character(),
  CPU_Time = numeric(),
  GPU_Time = numeric(),
  CPU_GFLOPS = numeric(),
  GPU_GFLOPS = numeric(),
  Speedup = numeric(),
  stringsAsFactors = FALSE
)

for (size in sizes) {
  size_mb <- size * 4 / 1024 / 1024
  cat(sprintf("Ğ Ğ°Ğ·Ğ¼ĞµÑ€: %.0e ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² (%.1f MB)\n", size, size_mb))

  # CPU benchmark
  cat("  CPU: ")
  cpu_result <- benchmark_cpu(size, iterations)
  cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", cpu_result$mean_time, cpu_result$gflops))

  # GPU benchmark
  if (vulkan_available) {
    cat("  GPU: ")
    gpu_result <- benchmark_gpu(size, iterations)
    if (!is.null(gpu_result)) {
      cat(sprintf("%.4f ÑĞµĞº (%.2f GFLOPS)\n", gpu_result$mean_time, gpu_result$gflops))

      speedup <- cpu_result$mean_time / gpu_result$mean_time
      cat(sprintf("  Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx %s\n", speedup,
                  ifelse(speedup > 1, "ğŸš€", "âš ï¸")))

      # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸
      if (max(abs(cpu_result$result - gpu_result$result)) < 1e-4) {
        cat("  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: âœ“ Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ‡Ğ½Ñ‹\n")
      } else {
        cat("  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹: âš ï¸ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ÑÑ‚ÑÑ\n")
      }

      results_table <- rbind(results_table, data.frame(
        Size = sprintf("%.0e", size),
        CPU_Time = cpu_result$mean_time,
        GPU_Time = gpu_result$mean_time,
        CPU_GFLOPS = cpu_result$gflops,
        GPU_GFLOPS = gpu_result$gflops,
        Speedup = speedup
      ))
    }
  } else {
    cat("  GPU: Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½\n")
  }

  cat("\n")
}

# ============================================================================
# Ğ¢ĞµÑÑ‚ 2: ĞœĞ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
# ============================================================================
if (vulkan_available) {
  cat("â•â•â• Ğ¢ĞµÑÑ‚ 2: ĞœĞ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ğ¾Ğµ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ â•â•â•\n\n")

  mat_sizes <- c(512, 1024, 2048)

  for (mat_size in mat_sizes) {
    n_elem <- mat_size * mat_size
    size_mb <- n_elem * 4 / 1024 / 1024

    cat(sprintf("ĞœĞ°Ñ‚Ñ€Ğ¸Ñ†Ğ°: %dx%d (%.1f MB)\n", mat_size, mat_size, size_mb))

    # CPU
    mem_size_cpu <- as.numeric(n_elem) * 4 * 4
    ctx_cpu <- ggml_init(mem_size = mem_size_cpu)
    ggml_set_no_alloc(ctx_cpu, TRUE)

    m1_cpu <- ggml_new_tensor_2d(ctx_cpu, GGML_TYPE_F32, mat_size, mat_size)
    m2_cpu <- ggml_new_tensor_2d(ctx_cpu, GGML_TYPE_F32, mat_size, mat_size)
    m3_cpu <- ggml_mul_mat(ctx_cpu, m1_cpu, m2_cpu)

    backend_cpu <- ggml_backend_cpu_init()
    ggml_backend_cpu_set_n_threads(backend_cpu, n_cores)
    buffer_cpu <- ggml_backend_alloc_ctx_tensors(ctx_cpu, backend_cpu)

    data_m1 <- rnorm(n_elem)
    data_m2 <- rnorm(n_elem)
    ggml_backend_tensor_set_data(m1_cpu, data_m1)
    ggml_backend_tensor_set_data(m2_cpu, data_m2)

    graph_cpu <- ggml_build_forward_expand(ctx_cpu, m3_cpu)

    # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ¸ Ğ·Ğ°Ğ¼ĞµÑ€
    ggml_backend_graph_compute(backend_cpu, graph_cpu)
    mat_iters <- if (mat_size <= 2048) 10 else if (mat_size <= 4096) 5 else 3
    time_cpu <- system.time({
      for (i in 1:mat_iters) {
        ggml_backend_graph_compute(backend_cpu, graph_cpu)
      }
    })[3] / mat_iters

    cat(sprintf("  CPU: %.4f ÑĞµĞº (%.2f GFLOPS)\n", time_cpu,
                2 * mat_size^3 / time_cpu / 1e9))

    # GPU
    mem_size_gpu <- as.numeric(n_elem) * 4 * 4
    ctx_gpu <- ggml_init(mem_size = mem_size_gpu)
    ggml_set_no_alloc(ctx_gpu, TRUE)

    m1_gpu <- ggml_new_tensor_2d(ctx_gpu, GGML_TYPE_F32, mat_size, mat_size)
    m2_gpu <- ggml_new_tensor_2d(ctx_gpu, GGML_TYPE_F32, mat_size, mat_size)
    m3_gpu <- ggml_mul_mat(ctx_gpu, m1_gpu, m2_gpu)

    backend_gpu <- ggml_vulkan_init(0)
    buffer_gpu <- ggml_backend_alloc_ctx_tensors(ctx_gpu, backend_gpu)

    ggml_backend_tensor_set_data(m1_gpu, data_m1)
    ggml_backend_tensor_set_data(m2_gpu, data_m2)

    graph_gpu <- ggml_build_forward_expand(ctx_gpu, m3_gpu)

    # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ¸ Ğ·Ğ°Ğ¼ĞµÑ€
    ggml_backend_graph_compute(backend_gpu, graph_gpu)
    time_gpu <- system.time({
      for (i in 1:mat_iters) {
        ggml_backend_graph_compute(backend_gpu, graph_gpu)
      }
    })[3] / mat_iters

    cat(sprintf("  GPU: %.4f ÑĞµĞº (%.2f GFLOPS)\n", time_gpu,
                2 * mat_size^3 / time_gpu / 1e9))
    cat(sprintf("  Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx %s\n\n", time_cpu / time_gpu,
                ifelse(time_cpu > time_gpu, "ğŸš€", "âš ï¸")))

    # Cleanup
    ggml_backend_buffer_free(buffer_cpu)
    ggml_backend_free(backend_cpu)
    ggml_free(ctx_cpu)

    ggml_backend_buffer_free(buffer_gpu)
    ggml_vulkan_free(backend_gpu)
    ggml_free(ctx_gpu)
  }
}

# ============================================================================
# Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°
# ============================================================================
if (nrow(results_table) > 0) {
  cat("\nâ•â•â• Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² â•â•â•\n\n")
  print(results_table, row.names = FALSE)

  cat("\nâ•â•â• Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° â•â•â•\n")
  cat(sprintf("Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ CPU: %.2f GFLOPS\n",
              mean(results_table$CPU_GFLOPS)))
  if (vulkan_available) {
    cat(sprintf("Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ GPU: %.2f GFLOPS\n",
                mean(results_table$GPU_GFLOPS)))
    cat(sprintf("Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ GPU vs CPU: %.2fx\n",
                mean(results_table$Speedup)))
    cat(sprintf("ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx\n",
                max(results_table$Speedup)))
    cat(sprintf("ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ: %.2fx\n",
                min(results_table$Speedup)))
  }
}

cat("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n")
cat("â•‘                         Ğ¢Ğ•Ğ¡Ğ¢Ğ« Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ«                        â•‘\n")
cat("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
