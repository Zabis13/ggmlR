
## –°—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ GGML API (v0.5.1+)

**–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ñ—É–Ω–∫—Ü–∏–π: 397**

---

## ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

### –Ø–¥—Ä–æ GGML
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: `ggml_init`, `ggml_free`, `ggml_reset`
- –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤: `ggml_new_tensor_1d/2d/3d/4d`, `ggml_dup_tensor`
- –î–æ—Å—Ç—É–ø –∫ –¥–∞–Ω–Ω—ã–º: `ggml_set_f32`, `ggml_get_f32`, `ggml_set_i32`, `ggml_get_i32`
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–Ω–∑–æ—Ä–∞—Ö: `ggml_nelements`, `ggml_nbytes`, `ggml_tensor_shape`, `ggml_tensor_type`

### –û–ø–µ—Ä–∞—Ü–∏–∏ (150+ —Ñ—É–Ω–∫—Ü–∏–π)
- **–ê—Ä–∏—Ñ–º–µ—Ç–∏–∫–∞**: add, sub, mul, div, scale, clamp (+ inplace –≤–∞—Ä–∏–∞–Ω—Ç—ã)
- **–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞**: sqr, sqrt, exp, log, abs, neg, sin, cos, ceil, floor, round
- **–ê–∫—Ç–∏–≤–∞—Ü–∏–∏**: relu, gelu, silu, sigmoid, tanh, elu, softplus, hardsigmoid, hardswish, leaky_relu
- **GLU**: glu, reglu, geglu, swiglu (+ split –≤–∞—Ä–∏–∞–Ω—Ç—ã)
- **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: norm, rms_norm, l2_norm, group_norm (+ inplace –≤–∞—Ä–∏–∞–Ω—Ç—ã)
- **Softmax**: soft_max, soft_max_ext (+ inplace –∏ back –≤–∞—Ä–∏–∞–Ω—Ç—ã)
- **–†–µ–¥—É–∫—Ü–∏—è**: sum, sum_rows, mean, argmax
- **–ú–∞—Ç—Ä–∏—á–Ω—ã–µ**: mul_mat, mul_mat_id, out_prod, transpose
- **Reshape/View**: reshape_1d/2d/3d/4d, view_1d/2d/3d/4d, permute, cont
- **CNN**: conv_1d, conv_2d, conv_transpose_1d, pool_1d, pool_2d, im2col
- **Attention**: flash_attn_ext, flash_attn_back, diag_mask_inf/zero
- **RoPE**: rope, rope_ext, rope_multi (+ inplace –∏ back –≤–∞—Ä–∏–∞–Ω—Ç—ã)

### Backend System (60+ —Ñ—É–Ω–∫—Ü–∏–π)
- **CPU Backend**: `ggml_backend_cpu_init`, `ggml_backend_cpu_set_n_threads`
- **Device Management**: `ggml_backend_dev_count/get/by_name/by_type`
- **Device Properties**: `ggml_backend_dev_name/description/memory/type/get_props`
- **Registry**: `ggml_backend_reg_count/get/by_name/dev_count/dev_get`
- **Buffer Management**: `ggml_backend_buffer_*` (free, get_size, name, clear, usage, is_host)
- **Events**: `ggml_backend_event_new/free/record/synchronize/wait`
- **Graph Plans**: `ggml_backend_graph_plan_create/free/compute`
- **Async Operations**: `ggml_backend_tensor_set/get/copy_async`
- **Scheduler**: `ggml_backend_sched_*` (new, free, reserve, alloc_graph, graph_compute, synchronize)
- **Init Helpers**: `ggml_backend_init_by_name/by_type/init_best`, `ggml_backend_load/load_all`

### Vulkan Backend (10 —Ñ—É–Ω–∫—Ü–∏–π)
- `ggml_vulkan_available`, `ggml_vulkan_device_count/description/memory`
- `ggml_vulkan_init`, `ggml_vulkan_free`, `ggml_vulkan_list_devices`

### Optimizer System (39 —Ñ—É–Ω–∫—Ü–∏–π)
- **Dataset**: `ggml_opt_dataset_init/free/ndata/data/labels/shuffle/get_batch`
- **Context**: `ggml_opt_init/free/reset/alloc/static_graphs`
- **Training**: `ggml_opt_fit`, `ggml_opt_epoch`, `ggml_opt_eval`, `ggml_opt_grad_acc`
- **Tensors**: `ggml_opt_inputs/outputs/labels/loss/pred/ncorrect`
- **Results**: `ggml_opt_result_init/free/reset/ndata/loss/accuracy/pred`
- **Constants**: loss types (mean, sum, cross_entropy, mse), optimizer types (adamw, sgd)

### CPU Feature Detection (28 —Ñ—É–Ω–∫—Ü–∏–π)
- **x86**: sse3, ssse3, avx, avx2, avx_vnni, bmi2, f16c, fma, avx512, avx512_vbmi/vnni/bf16, amx_int8
- **ARM**: neon, arm_fma, fp16_va, dotprod, matmul_int8, sve, sme + sve_cnt
- **Other**: riscv_v + rvv_vlen, vsx, vxe, wasm_simd, llamafile
- **Helper**: `ggml_cpu_features()` ‚Äî –≤—Å–µ —Ñ–∏—á–∏ –∫–∞–∫ named list

### Tensor Layout/Contiguity (9 —Ñ—É–Ω–∫—Ü–∏–π)
- `ggml_is_contiguous_0/1/2`, `ggml_is_contiguous_channels/rows`
- `ggml_is_contiguously_allocated`, `ggml_are_same_stride`
- `ggml_can_repeat`, `ggml_count_equal`

### Type System (10 —Ñ—É–Ω–∫—Ü–∏–π)
- `ggml_type_name`, `ggml_type_size`, `ggml_type_sizef`, `ggml_blck_size`
- `ggml_is_quantized`, `ggml_ftype_to_ggml_type`
- `ggml_op_name`, `ggml_op_symbol`, `ggml_op_desc`, `ggml_get_unary_op`

### Quantization (4 —Ñ—É–Ω–∫—Ü–∏–∏)
- `ggml_quantize_init`, `ggml_quantize_free`, `ggml_quantize_requires_imatrix`
- `ggml_quantize_chunk`

### Graph Operations
- `ggml_build_forward_expand`, `ggml_graph_compute`, `ggml_graph_compute_with_ctx`
- `ggml_graph_n_nodes`, `ggml_graph_node`, `ggml_graph_get_tensor`
- `ggml_graph_print`, `ggml_graph_reset`, `ggml_graph_dump_dot`, `ggml_graph_overhead`

### Memory Allocators
- `ggml_gallocr_new`, `ggml_gallocr_free`, `ggml_gallocr_reserve`
- `ggml_gallocr_alloc_graph`, `ggml_gallocr_get_buffer_size`
- `ggml_backend_alloc_ctx_tensors`

---

## üî¥ –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û (–ö—Ä–∏—Ç–∏—á–Ω—ã–µ)

- [ ] `ggml_backend_graph_compute_async()` ‚Äî async graph compute
- [ ] `ggml_backend_multi_buffer_*()` ‚Äî multi-buffer –æ–ø–µ—Ä–∞—Ü–∏–∏
- [ ] `ggml_backend_register()` ‚Äî dynamic backend registration

---

## üü° –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û (–°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)

### Advanced RoPE (1 —Ñ—É–Ω–∫—Ü–∏—è)
- [ ] `ggml_rope_multi_back()` ‚Äî backward –¥–ª—è multi-head RoPE
- ‚ö†Ô∏è `ggml_rope_custom*()` ‚Äî deprecated, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å rope_ext

### Graph Introspection (8 —Ñ—É–Ω–∫—Ü–∏–π)
- [ ] `ggml_build_backward_expand()` ‚Äî –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- [ ] `ggml_graph_add_node()` / `ggml_graph_clear()` / `ggml_graph_cpy()` / `ggml_graph_dup()`
- [ ] `ggml_graph_get_grad()` / `ggml_graph_get_grad_acc()`
- [ ] `ggml_graph_view()`, `ggml_cgraph_eval_order()`
- [ ] `ggml_op_can_inplace()`, `ggml_cplan()`

### Advanced Attention/Loss (6 —Ñ—É–Ω–∫—Ü–∏–π)
- [ ] `ggml_cross_entropy_loss()` / `ggml_cross_entropy_loss_back()`
- [ ] `ggml_cumsum()`
- [ ] `ggml_flash_attn_ext_add_sinks()`
- [ ] `ggml_flash_attn_ext_get_prec()` / `ggml_flash_attn_ext_set_prec()`

---

## üü¢ –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û (–ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)

### –ù–∏–∑–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è (100+ —Ñ—É–Ω–∫—Ü–∏–π)
Row-level –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–∏–ø–æ–≤: q4_0, q5_0, q8_0, q2_K-q8_K, iq2_xxs/xs/s, iq3_xxs/s, iq4_nl/xs, tq1_0, tq2_0, mxfp4.

‚ö†Ô∏è –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π `ggml_quantize_chunk()` —É–∂–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω.

### Custom Operations (5 —Ñ—É–Ω–∫—Ü–∏–π)
‚ö†Ô∏è –¢—Ä–µ–±—É—é—Ç C callback (—Å–ª–æ–∂–Ω–æ –≤ R)
- [ ] `ggml_custom()` / `ggml_custom_inplace()`
- [ ] `ggml_set_op_params*()`

### Logging & Debugging (2 —Ñ—É–Ω–∫—Ü–∏–∏)
‚ö†Ô∏è –¢—Ä–µ–±—É—é—Ç C callback
- [ ] `ggml_log_set()`, `ggml_set_abort_callback()`

### Internal Functions (–Ω–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è)
- `ggml_are_same_layout()` ‚Äî inline –≤ ggml-impl.h
- `ggml_can_fuse*()`, `ggml_check_edges()` ‚Äî —Ç—Ä–µ–±—É—é—Ç cgraph internals

---

## Use Cases Status

| Use Case | –°—Ç–∞—Ç—É—Å | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|----------|--------|-------------|
| Inference –Ω–∞ CPU | ‚úÖ –ü–æ–ª–Ω–∞—è | Backend, scheduler, –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ |
| Inference –Ω–∞ GPU (Vulkan) | ‚úÖ –ë–∞–∑–æ–≤–∞—è | Device discovery, compute |
| Multi-GPU | ‚úÖ –ë–∞–∑–æ–≤–∞—è | Scheduler, device management |
| –û–±—É—á–µ–Ω–∏–µ/Fine-tuning | ‚úÖ –ü–æ–ª–Ω–∞—è | ggml_opt_* (39 —Ñ—É–Ω–∫—Ü–∏–π) |
| –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ | ‚úÖ –ü–æ–ª–Ω–∞—è | 28+ inplace –æ–ø–µ—Ä–∞—Ü–∏–π |
| –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è | ‚úÖ –ë–∞–∑–æ–≤–∞—è | quantize_chunk, type system |
| –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ | ‚úÖ –ü–æ–ª–Ω–∞—è | CPU features, tensor layout, type info |
| Custom –æ–ø–µ—Ä–∞—Ü–∏–∏ | ‚ùå | –¢—Ä–µ–±—É—é—Ç C callbacks |

---

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [ ] –í–∏–Ω—å–µ—Ç–∫–∞: Vulkan backend tutorial
- [ ] –í–∏–Ω—å–µ—Ç–∫–∞: Multi-GPU inference
- [ ] –ü—Ä–∏–º–µ—Ä—ã –∫–≤–∞–Ω—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
- [ ] `ggml_cross_entropy_loss()` ‚Äî –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
- [ ] `ggml_build_backward_expand()` ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ backward graph

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
- [ ] –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ scheduler overhead
- [ ] –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–ø–∏–π –º–µ–∂–¥—É GPU
